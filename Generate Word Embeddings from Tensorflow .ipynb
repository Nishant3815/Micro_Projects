{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nr17754\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.contrib.layers import embed_sequence\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Deep Learning is a new area of Machine Learning research, which has been introduced with the objective of moving Machine Learning closer to one of its original goals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep Learning is a new area of Machine Learning research, which has been introduced with the objective of moving Machine Learning closer to one of its original goals'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "tokens_set = list(set(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep',\n",
       " 'Learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'new',\n",
       " 'area',\n",
       " 'of',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'research',\n",
       " ',',\n",
       " 'which',\n",
       " 'has',\n",
       " 'been',\n",
       " 'introduced',\n",
       " 'with',\n",
       " 'the',\n",
       " 'objective',\n",
       " 'of',\n",
       " 'moving',\n",
       " 'Machine',\n",
       " 'Learning',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'one',\n",
       " 'of',\n",
       " 'its',\n",
       " 'original',\n",
       " 'goals']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "for i,j in enumerate(tokens_set):\n",
    "    vocab[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " 'been': 1,\n",
       " 'area': 2,\n",
       " 'Learning': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'its': 6,\n",
       " 'Deep': 7,\n",
       " 'which': 8,\n",
       " 'original': 9,\n",
       " 'goals': 10,\n",
       " 'the': 11,\n",
       " 'one': 12,\n",
       " 'research': 13,\n",
       " 'objective': 14,\n",
       " 'with': 15,\n",
       " 'introduced': 16,\n",
       " 'has': 17,\n",
       " 'new': 18,\n",
       " 'a': 19,\n",
       " 'closer': 20,\n",
       " 'is': 21,\n",
       " 'Machine': 22,\n",
       " 'moving': 23}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep Learning is a new area of Machine Learning research, which has been introduced with the objective of moving Machine Learning closer to one of its original goals'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = []\n",
    "for i in tokens:\n",
    "    feature.append(vocab.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 3,\n",
       " 21,\n",
       " 19,\n",
       " 18,\n",
       " 2,\n",
       " 4,\n",
       " 22,\n",
       " 3,\n",
       " 13,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 1,\n",
       " 16,\n",
       " 15,\n",
       " 11,\n",
       " 14,\n",
       " 4,\n",
       " 23,\n",
       " 22,\n",
       " 3,\n",
       " 20,\n",
       " 5,\n",
       " 12,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 10]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_embedded = embed_sequence(ids=feature,vocab_size=len(vocab),embed_dim=12,scope='words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'words/embedding_lookup:0' shape=(29, 12) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3692498   0.38886267 -0.3782023   0.09997553  0.39729315 -0.1898434\n",
      "  0.11612272  0.08531848  0.30361545 -0.3651639  -0.3959816   0.33472484]\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print (sess.run(features_embedded[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
